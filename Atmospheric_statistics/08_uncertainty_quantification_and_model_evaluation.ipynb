{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089bc965",
   "metadata": {},
   "source": [
    "# Title: Uncertainty Quantification and Model Evaluation in Atmospheric Data\n",
    "\n",
    "\n",
    "Description: Hands-on Python notebook for quantifying uncertainty, propagating errors, evaluating models, and visualizing prediction confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 1. Import Required Libraries\n",
    "# =======================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 2. Simulate Observed and Predicted Atmospheric Data\n",
    "# =======================\n",
    "# Observed ozone measurements (ppb)\n",
    "y_obs = np.array([50.2, 49.8, 51.1, 50.5, 50.0])\n",
    "# Predicted values from a model\n",
    "y_pred = np.array([50.0, 50.2, 50.8, 50.3, 49.9])\n",
    "\n",
    "# Uncertainty in observations\n",
    "y_unc = np.array([0.3, 0.25, 0.4, 0.3, 0.35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 3. Measurement Uncertainty\n",
    "# =======================\n",
    "mean_val = np.mean(y_obs)\n",
    "std_val = np.std(y_obs, ddof=1)  # sample standard deviation\n",
    "conf_interval = 1.96 * std_val / np.sqrt(len(y_obs))  # 95% confidence interval\n",
    "\n",
    "print(f\"Observed mean: {mean_val:.2f} ± {conf_interval:.2f} ppb (95% CI)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 4. Model Evaluation Metrics\n",
    "# =======================\n",
    "mae = mean_absolute_error(y_obs, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_obs, y_pred))\n",
    "r2 = r2_score(y_obs, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 5. Cross-Validation Example\n",
    "# =======================\n",
    "# Simulate predictor variables for multivariate regression\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 3)\n",
    "y = X @ np.array([1.5, -2.0, 0.5]) + np.random.normal(0, 0.5, 100)\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(\"Cross-validated R² scores:\", scores)\n",
    "print(\"Mean R²:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 6. Monte Carlo Simulation for Prediction Uncertainty\n",
    "# =======================\n",
    "n_sim = 1000\n",
    "predictions = []\n",
    "\n",
    "for _ in range(n_sim):\n",
    "    X_perturbed = X + np.random.normal(0, 0.1, X.shape)\n",
    "    model.fit(X_perturbed, y)\n",
    "    predictions.append(model.predict(X_perturbed[0].reshape(1,-1))[0])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "mean_pred = predictions.mean()\n",
    "ci_lower = np.percentile(predictions, 2.5)\n",
    "ci_upper = np.percentile(predictions, 97.5)\n",
    "\n",
    "print(f\"Monte Carlo Prediction: {mean_pred:.3f} [{ci_lower:.3f}, {ci_upper:.3f}] 95% CI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c87fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 7. Visualizing Measurement and Prediction Uncertainty\n",
    "# =======================\n",
    "time = np.arange(len(y_obs))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "# Plot observed data with uncertainty\n",
    "plt.errorbar(time, y_obs, yerr=y_unc, fmt='o', label='Observed ± uncertainty')\n",
    "# Plot predicted values\n",
    "plt.plot(time, y_pred, 'r-', label='Predicted')\n",
    "# Shaded prediction interval\n",
    "plt.fill_between(time, y_pred-0.5, y_pred+0.5, color='red', alpha=0.2, label='Prediction interval')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('O3 [ppb]')\n",
    "plt.title('Observations and Model Predictions with Uncertainty')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29506b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 8. Summary\n",
    "# =======================\n",
    "print(\"\"\"\n",
    "Summary:\n",
    "- Quantified measurement uncertainty using standard deviation and confidence intervals.\n",
    "- Evaluated model performance using MAE, RMSE, and R².\n",
    "- Applied cross-validation for robust model evaluation.\n",
    "- Used Monte Carlo simulation to propagate input uncertainty and generate prediction intervals.\n",
    "- Visualized both measurement and prediction uncertainty for atmospheric observations.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15152fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef423e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9520657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
